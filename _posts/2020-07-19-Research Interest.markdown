---
layout: post
title: <font size="6" style="color:Dodgerblue; font-family:'Gilroy Extra Bold', Gilroy;"> RESEARCH INTEREST </font>
---
---
<font size="4em" style="color:black;"><font size="5em" style="color:black;">Human-Computer Interaction (HCI), Sensing Systems, and Ubiquitous Computing.<br></font>
My research objective is to develop devices that allow computers to acknowledge users’ intention along with the world around them, and use this information to contribute to human wellbeing and health.  </font>
<br>
<br>
<br>
<font size="4em" style="color:black;"><font size="5em" style="color:black;">News<br></font>
● Joined <a href="https://makinteract.kaist.ac.kr/">Makinteract</a> Lab, advised by Professor Andrea Bianchi - Industrial Design, KAIST(Korea Advanced Institute of Science and Technology) -Aug.2021.<br>
● <a href="http://www.newshyu.com/news/articleView.html?idxno=1001225">Won the Minister of Science and ICT Award (grand prize) in a Korea national practical research competition (X-CORPS Festival).</a> -Dec.2020<br>
● Won the grand prize in Hanyang University research competition (HX-CORPS Festival). -Nov.2020.<br>
● Received The Right Hands scholarship (100% Tuition for 4 semesters). -March.2019. <br>

<!--
Current smart devices and health monitoring devices have a limited understanding of the users (e.g., what the user is doing, how they feel) and have limited interaction (e.g., touch, typing). If they can recognize user's daily activity and emotion, these collected data over time will become a personal health record, which can be used to prevent or monitor diseases. Also, this understanding of the user will enable various interactions (\emph{e.g.}, mood therapy, medication intake notification, overall home care). Therefore, I am aspired to enhance input on computing devices by developing and implementing smart sensing systems for them, to augment human health and wellbeing.

To do this, I will 1) explore methods to deploy bio-signals as input to smart devices through implementing novel sensing techniques (\emph{e.g.} radio frequency (RF) signal, laser) and leveraging machine learning. Then, analyze this information to use them for user recognition (\textit{e.g.}, activity, emotion) and interaction. My former research utilizing wearable electromechanical sensors and bio-signal sensors to solicit information on and around the body would serve as a starting point. I believe this approach has the potential to benefit people ubiquitously since bio-signals from humans mostly have a similar form regardless of skin color or the language they speak. Also, in detecting user status -particularly emotional state- they tell the direct and "true" state of the user unlike other methods (\emph{e.g.}, visual-based facial expression data, voice) can be faked. Furthermore, I would like to 2) unlock methods to push the limit of single sensors and deploy ultra-sparse sensors. This will enable devices to become truly ubiquitous without the ubiquity of sensors, which can be applied to various uses such as recognizing people's everyday activity in a broad range, and community health sensing.
-->
